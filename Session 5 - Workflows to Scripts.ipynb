{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b208aa",
   "metadata": {},
   "source": [
    "# Session 5- Batch Analysis\n",
    "*Goal - learn how to use the QuPath-created workflow to apply your analysis pipeline to multiple images*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef653b",
   "metadata": {},
   "source": [
    "## 1. Generating the Raw Workflow  Script\n",
    "The workflow tab helps you remember what you've done by keeping track of *most* of the buttons you've pressed, including any *parameters* that you set (minimum size thresholds, classifier names, etc). We can use this record to create a script that can be run on a batch of images. \n",
    "  \n",
    "1. Start with LungImg2 open (the version with InstanSeg cell detections)\n",
    "2. Open the Workflow tab. It will have a long list of commands that you have tried. If you click on one, it will show you the parameters that you used. \n",
    "\n",
    "  <img src=\"Images/WorkflowTab.PNG\"> <br>\n",
    "\n",
    "4. At the bottom of the screen, click <kbd>Create workflow</kbd> \n",
    "\n",
    "5. You'll get a window with a list of commands that you've run. We're going to simplify that list by deleting anything unnecessary for analyzing the other images in the project. Therefore, delete (`highlight > right click > remove selected items`):\n",
    "  - All of the duplicates of \"Set image type\" , leaving only 1 copy \n",
    "  - All of the \"Cell detection\" lines that ran the built-in cell detection, because we are going to use InstanSeg \n",
    "  - All of the \"Delete selected objects\" or \"Clear detections\" commands, because they are only useful during optimization. \n",
    "  - All but the last \"Run InstanSeg model\" command\n",
    "\n",
    "    <img src=\"Images/DeleteWorkflowCommands.gif\">\n",
    "  \n",
    "6. This will leave you with a much shorter list of steps, though it still needs further editing.  Click `Create script` at the bottom to turn the workflow into a draft script. \n",
    "\n",
    "7. Expand the Script Editor window to make it easier to read. It will look something like this (your exact script will be different).\n",
    "\n",
    "<img src=\"Images/ScriptEx1.PNG\"> <br>\n",
    "**Don't be scared!** It may look overwhelming, but it is just a written-out version of the workflow window. For every item in the workflow, there's a line of code with nearly identical words. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17feec78",
   "metadata": {},
   "source": [
    "## 2. Editing the Script\n",
    "From here, we need to remove some extraneous lines and rearrange others to redo our work. Step-by-step, here is what we need the script to do:\n",
    "\n",
    "1. Set Image Type: `setImageType('FLUORESCENCE');` - this declares that this is a fluorescence image with multiple channels.\n",
    "<br>\n",
    "2. Segment the whole tissue. This will be one of the lines that starts `createAnnotationsFromPixelClassifier`. You will have a few of those in your starting script.  Inside the parenthesis are the parameters: Classifier name, Minimum object size, minimum hole size, and any checked options. These are the exact same parameters that you set when you created the object. Find the one with the Tissue annotation and 1000 for each of the size thresholds.\n",
    "\n",
    "    <img src=\"Images/ReadingCreateAnnots.PNG\"> <br>    \n",
    "Copy-paste this line to be the second line in the script. \n",
    "\n",
    "    <img src=\"Images/ScriptLine2.gif\">\n",
    "    <br><br>\n",
    "    \n",
    "3. Select the annotation we just made so that all subsequent steps are constrained to the tissue. We can do that with the command `selectObjectsByClassification(\"Region*\");` which selects all objects with the Region* class.  Copy-paste that to be the third line in the script.  \n",
    "<br>\n",
    "4. Next, we are going to perform cell segmentation. This is different from the order we originally performed the steps in. Creating the Tumor object *after* cell detection will prevent it from being deleted. The InstanSeg function to do this is multiple lines, starting with `qupath.ext.instanseg.core.InstanSeg.builder()` and ending with an indented line `    .detectObjects()`. Copy-paste that ENTIRE section to be the next part of the the code. \n",
    "\n",
    "  <img src=\"Images/InstanSegScriptLIne2.gif\">\n",
    "    \n",
    "    \n",
    "\n",
    "5. Last, we create the tumor annotation. This was also done with the function `createAnnotationsFromPixelClassifier`, but this time look for the one that says \"TumorPixelClassifier\" (or whatever you named your classifier).  Copy-paste that to be line 4.  Your parameters may look slightly different than mine.\n",
    "\n",
    "  <img src=\"Images/Script_TumorLine.PNG\"> <br>\n",
    "\n",
    " \n",
    "6. Delete all other lines after the `createAnnotationsFromPixelClassifier(\"TumorPixelClassifier\", 500.0, 500.0)`\n",
    "<br>\n",
    "\n",
    "7. Save the script! In the Script Editor window, `File > Save As`. This will generate a Scripts folder inside your project folder. Give it a meaningful name. \n",
    "\n",
    "    <img src=\"Images/ScriptingSaveAs.PNG\">\n",
    "\n",
    "8. My finished script is pasted below. If you need to, you can copy-paste it. However *You must change the path in line 5* to the location where QuPath downloaded the model on your computer. I recommend getting this from your workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setImageType('FLUORESCENCE');\n",
    "createAnnotationsFromPixelClassifier(\"Tissue\", 1000.0, 1000.0, \"INCLUDE_IGNORED\")\n",
    "selectObjectsByClassification(\"Region*\");\n",
    "qupath.ext.instanseg.core.InstanSeg.builder()\n",
    "    .modelPath(\"C:/Users/smcardle/Documents/InstanSeg Models/fluorescence_nuclei_and_cells\") \n",
    "    .device(\"cpu\")\n",
    "    .inputChannels([ColorTransforms.createChannelExtractor(\"Hoechst\"), ColorTransforms.createChannelExtractor(\"CD11c\"), ColorTransforms.createChannelExtractor(\"CD68\"), ColorTransforms.createChannelExtractor(\"CD163\"), ColorTransforms.createChannelExtractor(\"CD20\"), ColorTransforms.createChannelExtractor(\"CD4\"), ColorTransforms.createChannelExtractor(\"CD8a\"), ColorTransforms.createChannelExtractor(\"CD45RO\"), ColorTransforms.createChannelExtractor(\"PD1\"), ColorTransforms.createChannelExtractor(\"CD45\"), ColorTransforms.createChannelExtractor(\"S100a\")])\n",
    "    .outputChannels()\n",
    "    .tileDims(512)\n",
    "    .interTilePadding(16)\n",
    "    .nThreads(4)\n",
    "    .makeMeasurements(false)\n",
    "    .randomColors(false)\n",
    "    .build()\n",
    "    .detectObjects()\n",
    "createAnnotationsFromPixelClassifier(\"TumorPixelClassifier\", 500.0, 500.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44db68ed",
   "metadata": {},
   "source": [
    "## 3. Run the script\n",
    "We've gotten through the hardest part! Now, test the script.\n",
    "1. Delete all objects in your current image. `Objects > Delete > Delete all objects`\n",
    "\n",
    "2. In the script editor, `Run > Run` or press <kbd> Ctrl </kbd> + <kbd> R </kbd> \n",
    "\n",
    "  <img src=\"Images/RunRun.PNG\">\n",
    "  <br>\n",
    "3. While it's running, you will see it say \"(Running)\". Just wait and don't press anything.\n",
    "<img src=\"Images/ScriptRunning.PNG\">  \n",
    "  - If it worked, 2 annotations and thousands of cells appeared. Check the Annotations tab. If you see this **HOORAY!** <br>\n",
    "  - If not, there is an error somewhere. It will probably tell you about the error at the bottom of the Script Editor in red. <br>If you are in the room at the LJI Workshop, raise your hand. Otherwise, ask a question at forum.image.sc and include that error message. \n",
    "<br><br>\n",
    "4. Save the image file (main window, not the Script Editor).\n",
    "\n",
    "5. Now it's time to run on the other images. In the script editor <kbd> Run > Run for project </kbd>\n",
    "\n",
    "6. Select LungImg1.ome.tiff and LungImg3.ome.tiff (or whichever 2 images you have not yet processed). You can highlight them both at the same time by holdring <kbd> Ctrl </kbd>. Then, click the <kbd> > </kbd> to choose those images. Then hit <kbd>OK</kbd>.\n",
    "      <img src=\"Images/RunForProject.PNG\">\n",
    "  \n",
    "7. Hooray! You just ran your first batch script!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08623a8",
   "metadata": {},
   "source": [
    "\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
