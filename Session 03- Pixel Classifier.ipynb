{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009b7926",
   "metadata": {},
   "source": [
    "# Session 3 - Pixel Classifier\n",
    "*Goal: Learn how to use a machine-learning pixel classifier to segment Regions of Interest*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337645a9",
   "metadata": {},
   "source": [
    "## 1. Preparation\n",
    "1. First, export an image of your manual annotations using the method discussed in [Session1](./Session%2001-%20Visualization.ipynb#5.-Exporting-Region-Images) (`File > Export images > Rendered RGB (with overlays)`) <br>\n",
    "2. Delete the Tumor annotation, leave the tissue Region* annotation alone.<br> ![DeleteAnnotation.PNG](Images/DeleteAnnotation.PNG)\n",
    "3. Make sure the tissue annotation is locked (it should be already).  <br>\n",
    "<img src=\"Images/LockedAnnotation.PNG\"> <br>\n",
    "    - If you don't see the lock symbol, right click the annotation in the Annotation list and click `Lock`. <br>\n",
    "4. Turn on all channels except the blank channels. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee4e00f5",
   "metadata": {},
   "source": [
    "## 2. Train a Classifier\n",
    "1. Within the class list, select 'Tumor' and then click \"Auto set\" <br>\n",
    "![Autoset.PNG](Images/Autoset.PNG)\n",
    "\n",
    "2. Use the `Polyline` tool to draw some squiggles over the cancer region. <img src=\"https://qupath.readthedocs.io/en/0.5/_images/POLYLINE_TOOL.png\" width=\"50\"><br>\n",
    "These will be automatically assigned the \"Tumor\" class<br>\n",
    "Get near the edges without going over into the tissue stroma<br>\n",
    "3. Within the class list, click on 'Ignore*'\n",
    "4. Draw some lines over the non-cancer (S100 negative) region using the Polyline tool. Also draw 1 small line in the non-tissue background region\n",
    "5. Open up the classifier training window: `Classify > Pixel classification > Train pixel classifier`\n",
    "6. Click on `Live Prediction`\n",
    "7. You'll see results that look something like this:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31077ad9",
   "metadata": {},
   "source": [
    "![PixelClassifierRound1.PNG](Images/PixelClassifierRound1.PNG)\n",
    "\n",
    "If you can't see anything, make sure the C button is selected and that the transparency slider is all the way to the right\n",
    " <img src=\"Images/ClassificationOn.PNG\">\n",
    "\n",
    "\n",
    "7. **Iterate!** Add new annotations to correct errors until the results looks better. You'll find that some small issues won't go away with additional training.\n",
    "\n",
    "8. **Adjust Classifier Features and Settings** Choosing the best features and settings for a classifier is both essential and complex. We'll begin talking about it now, and we'll keep coming back to it throughout the course. \n",
    "\n",
    "    1. Increase the resolution (lower pixel size) to smooth the results, decrease the resolution (higher pixel size) to make it process faster\n",
    "    2. To change the features that the ML algorithm uses for its math, click \"Edit\" next to \"Default Multiscale Features\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40deafc2",
   "metadata": {},
   "source": [
    "\n",
    "![EditFeatures.PNG](Images/EditFeatures.PNG)\n",
    "\n",
    "Recommended settings for this example:\n",
    "  - Resolution: High (1.30 um/pixel)\n",
    "  - Channels: Hoechst, AF1, PDL1, CD45, S100a\n",
    "  - Scales: 1.0, 2.0, 4.0\n",
    "  - Features:  Gaussian, Laplacian of Gaussian\n",
    "  \n",
    "9. Iterate until you are happy. \n",
    "\n",
    "10. In the classifier training window, name your classifier 'TumorPixelClassifier' and click <kbd>Save</kbd>\n",
    "\n",
    "10. In the main window - `File > Save` to save your image and training annotations. *DO IT NOW.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "535cddc3",
   "metadata": {},
   "source": [
    "## 3. Include multiple images in training\n",
    "A classifier trained on a single image *cannot be extrapolated* to other images. You must always train on a representative sample of the data in your project. \n",
    "\n",
    "1. Double check that you have saved your current image.\n",
    "2. Within the Project tab, double click on LungImg1.ome.tiff to open it.\n",
    "\n",
    "![ProjectTab.PNG](Images/ProjectTab.PNG)\n",
    "\n",
    "  The classifier probably does not look good!  \n",
    "\n",
    "3. Load the LungImg2 training data. Within the classifier trianing window, go to: <kbd>Load training</kbd>, select LungImg2.ome.tiff, then click <kbd> \\> </kbd> and <kbd> Apply </kbd>\n",
    "\n",
    "<img src=\"Images/LoadTraining.PNG\" width=\"600\">\n",
    "\n",
    "4. Add new training annotations to improve the classifier. Also, try adjusting the features, sizes, and channels to see how these paramters affect the results. \n",
    "\n",
    "5. When it looks (acceptably) good, repeat steps 2-4 above with LungImg3. \n",
    "\n",
    "6. At the end, revisit LungImg2 to make sure these changes didn't ruin anything. \n",
    "\n",
    "7. Save the classifier. It will ask you if you want to overwrite the existing file- click Yes.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5f5cf",
   "metadata": {},
   "source": [
    "## 4. Creating Objects using the classifier\n",
    "The classifier itself is just a way to determine if a pixel belongs to the tumor or not, depending on intensity and context. Creating the object that outlines the tumor (segmentation) is a separate step. \n",
    "\n",
    "1. Before creating the object, we are going to save a copy of our training annotations. First, save your current image! Then, go to your project folder by right clicking on the name of any image in the Project tab and selecting `Open directory > Project...` \n",
    "<img src=\"Images/ProjectDir.PNG\">\n",
    "2. Go up one more folder to copy-paste the entire QuPath project folder to create a duplicate. Name it something like 'Tumor Classifier Training'\n",
    "\n",
    "3. Make sure you have LungImg2 open. To delete all of the training annotations, hold <kbd>Ctrl</kbd> and click on the classes 'Tumor' and 'Ignore*'. Then, `right click > Select objects by classification`. Then,  <kbd>Delete</kbd>\n",
    "<img src=\"Images/SelectByClass.gif\">\n",
    "\n",
    "4. Load the pixel classifier: `Classify > Pixel classification > Load Pixel Classifier`. In the dropdown, choose the Tumor clasisfier you just made. \n",
    "\n",
    "5. Select the Tissue annotation by using the same process as Step 3. Select the 'Region*' class, `right click > Select objects by classification`. With it selected, in the Load pixel classifier window, click `Create Objects` and when it asks about Parent Objects, choose `Current Selection` <br>\n",
    "<img src=\"Images/CreateObjectsPC.PNG\">\n",
    "\n",
    "6. This will bring up the Create objects window, similar to when we [created the tissue annotation.](./Session%2002-%20Tissue%20Annotations.ipynb#1.-Create-a-Tissue-Annotation-to-define-the-tissue-area) Use these settings:\n",
    "  - New object type: Annotation\n",
    "  - Minimum object size: 500\n",
    "  - Minimum hole size: 500\n",
    "  \n",
    "7. The Tumor region should be a \"child\" of the tissue region. To validate, look at your Hierarchy tab. The tumor should be \"under\" the Region* annotation.  <br>\n",
    "<img src=\"Images/ChildObjHier.gif\">\n",
    "\n",
    "If they are the same level, delete the tumor, select the tissue, and then remake the tumor. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
